{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.7.0\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "\n",
    "\n",
    "# Check core SDK version number.\n",
    "print('SDK version:', azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing interactive authentication. Please follow the instructions on the terminal.\n",
      "To sign in, use a web browser to open the page https://microsoft.com/devicelogin and enter the code ANTQYUJ64 to authenticate.\n",
      "Interactive authentication successfully completed.\n",
      "hakk-ai\n",
      "hakk.ai\n",
      "eastus\n",
      "b738af92-69d2-4390-a1d8-579dc094b72e\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model finalized_model\n",
      "Name: finalized_model\n",
      "Version: 3\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path=\"Model/final_model.pkl\",\n",
    "                       model_name=\"finalized_model\",\n",
    "                       workspace=ws)\n",
    "\n",
    "print('Name:', model.name)\n",
    "print('Version:', model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "\n",
    "# Usually a good idea to choose specific version numbers\n",
    "# so training is made on same packages as scoring\n",
    "myenv = CondaDependencies.create(\n",
    "    conda_packages=[\n",
    "        'numpy==1.15.4',\n",
    "        'scikit-learn==0.19.1', \n",
    "        'pandas==0.23.4',        \n",
    "        'joblib',\n",
    "        'xgboost'\n",
    "    ],\n",
    "    pip_packages=[\n",
    "        'azureml-defaults>=1.0.45',\n",
    "        'inference-schema[numpy-support]',\n",
    "        'inference-schema[pandas-support]'\n",
    "    ], \n",
    "    python_version='3.6.2')\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "import xgboost a\n",
    "import pandas as pd\n",
    "\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
    "\n",
    "def haversine_km(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6367 * c\n",
    "    return km\n",
    "\n",
    "def haversine_m(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.    \n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    m = 3956 * c\n",
    "    return m\n",
    "\n",
    "def preprocessing(data):\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='s')\n",
    "    data['timestamp'] = pd.DatetimeIndex(data.timestamp)\n",
    "\n",
    "    data['is_weekend'] = np.where(data['day_of_week'].isin([5,6]), 1, 0)\n",
    "    data['is_weekday'] = np.where(data['day_of_week'].isin([5,6]), 0, 1)\n",
    "\n",
    "    data['is_wee_hours'] = np.where(data['hour_of_day'].isin([17,18,19,20,21]), 1, 0)\n",
    "\n",
    "    data['is_rush_hours_morning'] = np.where(data.timestamp.dt.strftime('%H:%M:%S').between('11:30:00', '01:30:00'), 1, 0)\n",
    "    data['is_rush_hours_evening'] = np.where(data.timestamp.dt.strftime('%H:%M:%S').between('09:00:00', '12:00:00'), 1, 0)\n",
    "\n",
    "    data['sin_hour_of_day'] = np.sin(2*np.pi*data.hour_of_day/24)\n",
    "    data['cos_hour_of_day'] = np.cos(2*np.pi*data.hour_of_day/24)\n",
    "    data['sin_day_of_week'] = np.sin(2*np.pi*data.day_of_week/7)\n",
    "    data['cos_day_of_week'] = np.cos(2*np.pi*data.day_of_week/7)\n",
    "\n",
    "\n",
    "    data['haversine_km'] = haversine_km(data['longitude_origin'], data['latitude_origin'], \n",
    "                                 data['longitude_destination'], data['latitude_destination'])\n",
    "\n",
    "    data['haversine_m'] = haversine_m(data['longitude_origin'], data['latitude_origin'], \n",
    "                                 data['longitude_destination'], data['latitude_destination'])\n",
    "\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "    coords = np.vstack((data[['latitude_origin', 'longitude_origin']].values,\n",
    "                    data[['latitude_destination', 'longitude_destination']].values))\n",
    "    \n",
    "    pca = PCA().fit(coords)\n",
    "\n",
    "    data['pickup_pca0'] = pca.transform(data[['latitude_origin', 'longitude_origin']])[:, 0]\n",
    "    data['pickup_pca1'] = pca.transform(data[['latitude_origin', 'longitude_origin']])[:, 1]\n",
    "    data['dropoff_pca0'] = pca.transform(data[['latitude_destination', 'longitude_destination']])[:, 0]\n",
    "    data['dropoff_pca1'] = pca.transform(data[['latitude_destination', 'longitude_destination']])[:, 1]\n",
    "\n",
    "    data = data.drop(['timestamp'], axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "\n",
    "    model_path = Model.get_model_path(model_name='finalized_model')\n",
    "    bst = xgb.Booster({'nthread': 1})  # init model\n",
    "    model = bst.load_model(model_path)  # load data\n",
    "    #model = joblib.load(model_path)\n",
    "\n",
    "    \n",
    "input_sample = pd.DataFrame(data=[{\n",
    "    \"latitude_origin\": -6.141255,\n",
    "    \"longitude_origin\": 106.692710,\n",
    "    \"latitude_destination\": -6.141150,\n",
    "    \"longitude_destination\": 106.693154,\n",
    "    \"timestamp\": 1590487113,\n",
    "    \"hour_of_day\": 9,\n",
    "    \"day_of_week\": 1\n",
    "}])\n",
    "\n",
    "# This is an integer type sample. Use the data type that reflects the expected result.\n",
    "output_sample = np.array([360.00])\n",
    "\n",
    "# To indicate that we support a variable length of data input,\n",
    "# set enforce_shape=False\n",
    "@input_schema('data', PandasParameterType(input_sample, enforce_shape=False))\n",
    "@output_schema(NumpyParameterType(output_sample))\n",
    "def run(data):\n",
    "    try:\n",
    "        #preprocessing\n",
    "        data = preprocessing(data)\n",
    "        #result\n",
    "        result = model.predict(data)    \n",
    "        return result.tolist()\n",
    "    \n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model finalized_model:3 to /tmp/azureml_jcau78vq/finalized_model/3\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry hakkai6fb3fa5e.azurecr.io\n",
      "Logging into Docker registry hakkai6fb3fa5e.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM hakkai6fb3fa5e.azurecr.io/azureml/azureml_73d03d5fb609b949b5587123a3620e38\n",
      " ---> fc9efa5255e2\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> 6b8920f79043\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6ImI3MzhhZjkyLTY5ZDItNDM5MC1hMWQ4LTU3OWRjMDk0YjcyZSIsInJlc291cmNlR3JvdXBOYW1lIjoiaGFray5haSIsImFjY291bnROYW1lIjoiaGFray1haSIsIndvcmtzcGFjZUlkIjoiYTkxYzQ5YjUtN2RlMC00Yzg4LTk3ZDAtOTdiNjVjMzgwODE3In0sIm1vZGVscyI6e30sIm1vZGVsc0luZm8iOnt9fQ== | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in 76c22b96c220\n",
      " ---> 1b8906b5ee67\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpmq2kehhs.py' /var/azureml-app/main.py\n",
      " ---> Running in 70cbb8b4e39a\n",
      " ---> cc62224f42aa\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in feecccf68468\n",
      " ---> fd1c16312c33\n",
      "Successfully built fd1c16312c33\n",
      "Successfully tagged hakkai-service-test:latest\n",
      "Container (name:mystifying_edison, id:a6e93a6c61d9d0bedb7aa095991457198b4920de4b162ff4e551b6ecc69da516) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:8fa878a00e7ea53cbaad15c4d19b6d56eebcff48c02a9b94c7039a3120dd2cb9 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Error: Container has crashed. Did your init method fail?\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Container Logs:\n",
      "2020-06-19T21:51:17,685909464+00:00 - gunicorn/run \n",
      "2020-06-19T21:51:17,688731570+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2020-06-19T21:51:17,694559081+00:00 - iot-server/run \n",
      "2020-06-19T21:51:17,698720889+00:00 - rsyslog/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-06-19T21:51:17,786006862+00:00 - iot-server/finish 1 0\n",
      "2020-06-19T21:51:17,787240264+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 39\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "User's init function failed\n",
      "Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 162, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/main.py\", line 94, in init\n",
      "    bst = xgb.Booster({'nthread': 4})  # init model\n",
      "NameError: name 'xgb' is not defined\n",
      "\n",
      "Worker exiting (pid: 39)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2020-06-19T21:51:19,261396778+00:00 - gunicorn/finish 3 0\n",
      "2020-06-19T21:51:19,262539580+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-abaf59a3d4e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                        \u001b[0minference_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                        deployment_config=deployment_config)\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[1;32m     70\u001b[0m                                           logger=module_logger)\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    599\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                                    \u001b[0mhealth_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_base_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m                                    cleanup_if_failed=False)\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTATE_RUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36mcontainer_health_check\u001b[0;34m(docker_port, container, health_url, cleanup_if_failed)\u001b[0m\n\u001b[1;32m    745\u001b[0m             \u001b[0;31m# The container has started and crashed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m             _raise_for_container_failure(container, cleanup_if_failed,\n\u001b[0;32m--> 747\u001b[0;31m                                          'Error: Container has crashed. Did your init method fail?')\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# The container hasn't crashed, so try to ping the health endpoint.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/_model_management/_util.py\u001b[0m in \u001b[0;36m_raise_for_container_failure\u001b[0;34m(container, cleanup, message)\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mcleanup_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1260\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Error: Container has crashed. Did your init method fail?\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Error: Container has crashed. Did your init method fail?\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Webservice\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig, Model\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "service_name = 'hakkai-service-test'\n",
    "\n",
    "# Remove any existing service under the same name.\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    pass\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"env\", file_path=\"myenv.yml\")\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=myenv)\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=8890)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=deployment_config)\n",
    "service.wait_for_deployment(show_output=True)\n",
    "\n",
    "print(service.port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-19T21:25:49,253973093+00:00 - rsyslog/run \n",
      "2020-06-19T21:25:49,257155899+00:00 - gunicorn/run \n",
      "2020-06-19T21:25:49,257777400+00:00 - iot-server/run \n",
      "2020-06-19T21:25:49,258911602+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-06-19T21:25:49,351894487+00:00 - iot-server/finish 1 0\n",
      "2020-06-19T21:25:49,353170589+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 39\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "User's init function failed\n",
      "Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 162, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/main.py\", line 95, in init\n",
      "    model = joblib.load(model_path)\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 585, in load\n",
      "    obj = _unpickle(fobj, filename, mmap_mode)\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 504, in _unpickle\n",
      "    obj = unpickler.load()\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/pickle.py\", line 1050, in load\n",
      "    dispatch[key[0]](self)\n",
      "KeyError: 0\n",
      "\n",
      "Worker exiting (pid: 39)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2020-06-19T21:25:50,812691380+00:00 - gunicorn/finish 3 0\n",
      "2020-06-19T21:25:50,813926282+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy on cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running.............................................................................................................................................................................................................................................................................................................."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR - Received bad response from Resource Provider:\n",
      "Response Code: 500\n",
      "Headers: {'Date': 'Fri, 19 Jun 2020 21:07:33 GMT', 'Content-Type': 'text/html', 'Content-Length': '170', 'Connection': 'close', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\n",
      "Content: b'<html>\\r\\n<head><title>500 Internal Server Error</title></head>\\r\\n<body>\\r\\n<center><h1>500 Internal Server Error</h1></center>\\r\\n<hr><center>nginx</center>\\r\\n</body>\\r\\n</html>\\r\\n'\n",
      "\n",
      "ERROR - Received bad response from Resource Provider:\n",
      "Response Code: 500\n",
      "Headers: {'Date': 'Fri, 19 Jun 2020 21:07:33 GMT', 'Content-Type': 'text/html', 'Content-Length': '170', 'Connection': 'close', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\n",
      "Content: b'<html>\\r\\n<head><title>500 Internal Server Error</title></head>\\r\\n<body>\\r\\n<center><h1>500 Internal Server Error</h1></center>\\r\\n<hr><center>nginx</center>\\r\\n</body>\\r\\n</html>\\r\\n'\n",
      "\n"
     ]
    },
    {
     "ename": "WebserviceException",
     "evalue": "WebserviceException:\n\tMessage: Received bad response from Resource Provider:\nResponse Code: 500\nHeaders: {'Date': 'Fri, 19 Jun 2020 21:07:33 GMT', 'Content-Type': 'text/html', 'Content-Length': '170', 'Connection': 'close', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'<html>\\r\\n<head><title>500 Internal Server Error</title></head>\\r\\n<body>\\r\\n<center><h1>500 Internal Server Error</h1></center>\\r\\n<hr><center>nginx</center>\\r\\n</body>\\r\\n</html>\\r\\n'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Resource Provider:\\nResponse Code: 500\\nHeaders: {'Date': 'Fri, 19 Jun 2020 21:07:33 GMT', 'Content-Type': 'text/html', 'Content-Length': '170', 'Connection': 'close', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'<html>\\\\r\\\\n<head><title>500 Internal Server Error</title></head>\\\\r\\\\n<body>\\\\r\\\\n<center><h1>500 Internal Server Error</h1></center>\\\\r\\\\n<hr><center>nginx</center>\\\\r\\\\n</body>\\\\r\\\\n</html>\\\\r\\\\n'\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_get_operation_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Internal Server Error for url: https://eastus.modelmanagement.azureml.net/modelmanagement/v1.0/subscriptions/b738af92-69d2-4390-a1d8-579dc094b72e/resourceGroups/hakk.ai/providers/Microsoft.MachineLearningServices/workspaces/hakk-ai/operations/cddc059e-384d-4ed6-8f6a-ed967502ec4c",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m             \u001b[0moperation_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_operation_to_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_deployment_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_wait_for_operation_to_complete\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_operation_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36m_get_operation_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m                                       \u001b[0;34m'Content: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                                       logger=module_logger)\n\u001b[0m\u001b[1;32m    733\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Received bad response from Resource Provider:\nResponse Code: 500\nHeaders: {'Date': 'Fri, 19 Jun 2020 21:07:33 GMT', 'Content-Type': 'text/html', 'Content-Length': '170', 'Connection': 'close', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'<html>\\r\\n<head><title>500 Internal Server Error</title></head>\\r\\n<body>\\r\\n<center><h1>500 Internal Server Error</h1></center>\\r\\n<hr><center>nginx</center>\\r\\n</body>\\r\\n</html>\\r\\n'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Resource Provider:\\nResponse Code: 500\\nHeaders: {'Date': 'Fri, 19 Jun 2020 21:07:33 GMT', 'Content-Type': 'text/html', 'Content-Length': '170', 'Connection': 'close', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'<html>\\\\r\\\\n<head><title>500 Internal Server Error</title></head>\\\\r\\\\n<body>\\\\r\\\\n<center><h1>500 Internal Server Error</h1></center>\\\\r\\\\n<hr><center>nginx</center>\\\\r\\\\n</body>\\\\r\\\\n</html>\\\\r\\\\n'\"\n    }\n}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebserviceException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fd7b6554a14a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                        \u001b[0minference_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                        deployment_config=aci_config)\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/webservice/webservice.py\u001b[0m in \u001b[0;36mwait_for_deployment\u001b[0;34m(self, show_output)\u001b[0m\n\u001b[1;32m    684\u001b[0m                                           'Current state is {}'.format(self.state), logger=module_logger)\n\u001b[1;32m    685\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mWebserviceException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule_logger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait_for_operation_to_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWebserviceException\u001b[0m: WebserviceException:\n\tMessage: Received bad response from Resource Provider:\nResponse Code: 500\nHeaders: {'Date': 'Fri, 19 Jun 2020 21:07:33 GMT', 'Content-Type': 'text/html', 'Content-Length': '170', 'Connection': 'close', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\nContent: b'<html>\\r\\n<head><title>500 Internal Server Error</title></head>\\r\\n<body>\\r\\n<center><h1>500 Internal Server Error</h1></center>\\r\\n<hr><center>nginx</center>\\r\\n</body>\\r\\n</html>\\r\\n'\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Received bad response from Resource Provider:\\nResponse Code: 500\\nHeaders: {'Date': 'Fri, 19 Jun 2020 21:07:33 GMT', 'Content-Type': 'text/html', 'Content-Length': '170', 'Connection': 'close', 'Strict-Transport-Security': 'max-age=15724800; includeSubDomains; preload'}\\nContent: b'<html>\\\\r\\\\n<head><title>500 Internal Server Error</title></head>\\\\r\\\\n<body>\\\\r\\\\n<center><h1>500 Internal Server Error</h1></center>\\\\r\\\\n<hr><center>nginx</center>\\\\r\\\\n</body>\\\\r\\\\n</html>\\\\r\\\\n'\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "from azureml.core import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "\n",
    "service_name = 'finalized-service'\n",
    "\n",
    "# Remove any existing service under the same name.\n",
    "try:\n",
    "    Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "    pass\n",
    "\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"env\", file_path=\"myenv.yml\")\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score.py', environment=myenv)\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=3, memory_gb=15, enable_app_insights=True)\n",
    "\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name=service_name,\n",
    "                       models=[model],\n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config)\n",
    "service.wait_for_deployment(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "2020-06-19T21:09:27,516022071+00:00 - iot-server/run \n",
      "2020-06-19T21:09:27,517363377+00:00 - gunicorn/run \n",
      "2020-06-19T21:09:27,518810284+00:00 - rsyslog/run \n",
      "2020-06-19T21:09:27,523375505+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2020-06-19T21:09:27,598231752+00:00 - iot-server/finish 1 0\n",
      "2020-06-19T21:09:27,599691659+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (11)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 40\n",
      "Initialized PySpark session.\n",
      "Initializing logger\n",
      "Starting up app insights client\n",
      "Starting up request id generator\n",
      "Starting up app insight hooks\n",
      "Invoking user's init function\n",
      "User's init function failed\n",
      "Encountered Exception Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/aml_blueprint.py\", line 162, in register\n",
      "    main.init()\n",
      "  File \"/var/azureml-app/main.py\", line 35, in init\n",
      "    driver_module.init()\n",
      "  File \"/var/azureml-app/score.py\", line 95, in init\n",
      "    model = joblib.load(model_path)\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 585, in load\n",
      "    obj = _unpickle(fobj, filename, mmap_mode)\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 504, in _unpickle\n",
      "    obj = unpickler.load()\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/pickle.py\", line 1050, in load\n",
      "    dispatch[key[0]](self)\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/site-packages/joblib/numpy_pickle.py\", line 329, in load_build\n",
      "    Unpickler.load_build(self)\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/pickle.py\", line 1507, in load_build\n",
      "    setstate(state)\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/site-packages/xgboost/core.py\", line 1094, in __setstate__\n",
      "    _LIB.XGBoosterUnserializeFromBuffer(handle, ptr, length))\n",
      "  File \"/azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/site-packages/xgboost/core.py\", line 189, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [21:09:29] /home/conda/feedstock_root/build_artifacts/xgboost_1588600955503/work/src/learner.cc:682: Check failed: header == serialisation_header_: \n",
      "\n",
      "  If you are loading a serialized model (like pickle in Python) generated by older\n",
      "  XGBoost, please export the model by calling `Booster.save_model` from that version\n",
      "  first, then load it back in current version.  There's a simple script for helping\n",
      "  the process. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/latest/tutorials/saving_model.html\n",
      "\n",
      "  for reference to the script, and more details about differences between saving model and\n",
      "  serializing.\n",
      "\n",
      "\n",
      "Stack trace:\n",
      "  [bt] (0) /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libxgboost.so(+0x8871f) [0x7f6bda0b671f]\n",
      "  [bt] (1) /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libxgboost.so(+0x18895e) [0x7f6bda1b695e]\n",
      "  [bt] (2) /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/libxgboost.so(XGBoosterUnserializeFromBuffer+0x5e) [0x7f6bda0b89ee]\n",
      "  [bt] (3) /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7f6bf21bcec0]\n",
      "  [bt] (4) /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7f6bf21bc87d]\n",
      "  [bt] (5) /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7f6bf23d180e]\n",
      "  [bt] (6) /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x12245) [0x7f6bf23d2245]\n",
      "  [bt] (7) /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/bin/python(_PyObject_FastCallDict+0x8b) [0x557de95493cb]\n",
      "  [bt] (8) /azureml-envs/azureml_a0677afa4eacaa88546a43bc78063d41/bin/python(+0x19efce) [0x557de95dcfce]\n",
      "\n",
      "\n",
      "\n",
      "Worker exiting (pid: 40)\n",
      "Shutting down: Master\n",
      "Reason: Worker failed to boot.\n",
      "2020-06-19T21:09:29,234228541+00:00 - gunicorn/finish 3 0\n",
      "2020-06-19T21:09:29,235616448+00:00 - Exit code 3 is not normal. Killing image.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
